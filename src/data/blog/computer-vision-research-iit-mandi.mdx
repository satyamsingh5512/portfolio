---
title: 'Computer Vision Research at IIT Mandi: Small Object Detection in Remote Sensing'
description: 'My experience as a Research Intern at IIT Mandi working on FFCA-YOLO model for small object detection in remote sensing applications'
image: '/blog/iit-mandi-research.png'
tags: ['research', 'computer-vision', 'ai-ml', 'remote-sensing']
date: '2025-07-15'
isPublished: true
---

## Introduction

This summer, I had the incredible opportunity to work as a Research Intern at the Indian Institute of Technology (IIT) Mandi, focusing on computer vision applications in remote sensing. My research centered around small object detection using the FFCA-YOLO (Feature Fusion and Channel Attention YOLO) model.

## The Challenge: Small Object Detection in Remote Sensing

Remote sensing applications, particularly those involving satellite and drone imagery, present unique challenges for object detection:

### Why Small Objects Matter

In remote sensing imagery, objects of interest are often:
- **Vehicles** in traffic monitoring
- **Buildings** in urban planning
- **Ships** in maritime surveillance  
- **Agricultural equipment** in crop monitoring

These objects typically occupy less than 1% of the total image area, making them extremely difficult to detect using traditional computer vision approaches.

### Technical Challenges

1. **Scale Variation**: Objects appear at different scales depending on altitude
2. **Low Resolution**: Limited pixel information for small objects
3. **Background Complexity**: Cluttered backgrounds in aerial imagery
4. **Real-time Requirements**: Need for fast inference in practical applications

## FFCA-YOLO: Our Approach

### Feature Fusion Architecture

The FFCA-YOLO model incorporates several key innovations:

```python
# Simplified architecture overview
class FFCA_YOLO(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = CSPDarknet()
        self.neck = PANet_with_FFCA()
        self.head = YOLOHead()
        
    def forward(self, x):
        features = self.backbone(x)
        enhanced_features = self.neck(features)
        predictions = self.head(enhanced_features)
        return predictions
```

### Channel Attention Mechanism

The channel attention module helps the model focus on the most informative feature channels:

- **Squeeze**: Global average pooling to capture channel statistics
- **Excitation**: Two fully connected layers to model channel dependencies
- **Scale**: Multiply original features with attention weights

### Multi-Scale Feature Fusion

Our approach combines features from different scales to better detect small objects:

1. **Low-level features**: Rich spatial information
2. **High-level features**: Semantic information
3. **Fusion strategy**: Weighted combination based on object size

## Implementation Details

### GPU-Accelerated Training

Using PyTorch and CUDA, we optimized the training pipeline:

```python
# CUDA optimization for training
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = FFCA_YOLO().to(device)

# Mixed precision training for faster convergence
scaler = torch.cuda.amp.GradScaler()

for batch in dataloader:
    with torch.cuda.amp.autocast():
        predictions = model(batch['images'])
        loss = compute_loss(predictions, batch['targets'])
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

### Data Augmentation Strategy

To improve model robustness, we implemented:
- **Mosaic augmentation**: Combining 4 images into one
- **MixUp**: Blending images and labels
- **Geometric transformations**: Rotation, scaling, flipping
- **Photometric augmentations**: Brightness, contrast, saturation

## Results and Performance

### Quantitative Results

Our FFCA-YOLO model achieved significant improvements:

| Metric | Baseline YOLO | FFCA-YOLO | Improvement |
|--------|---------------|-----------|-------------|
| mAP@0.5 | 72.3% | 78.9% | +6.6% |
| mAP@0.5:0.95 | 45.2% | 52.1% | +6.9% |
| FPS | 45 | 42 | -3 |
| Model Size | 25.4MB | 28.1MB | +2.7MB |

### Qualitative Analysis

The model showed particular strength in:
- **Dense object scenarios**: Multiple small objects in close proximity
- **Challenging backgrounds**: Complex terrain and weather conditions
- **Multi-scale detection**: Objects at various distances from camera

## Real-time Inference Pipeline

### Optimization Techniques

For deployment, we implemented several optimization strategies:

```python
# TensorRT optimization for inference
import tensorrt as trt

def build_engine(onnx_path):
    logger = trt.Logger(trt.Logger.WARNING)
    builder = trt.Builder(logger)
    network = builder.create_network()
    parser = trt.OnnxParser(network, logger)
    
    # Parse ONNX model
    with open(onnx_path, 'rb') as model:
        parser.parse(model.read())
    
    # Build optimized engine
    config = builder.create_builder_config()
    config.max_workspace_size = 1 << 30  # 1GB
    engine = builder.build_engine(network, config)
    
    return engine
```

### Performance Metrics

- **Inference Speed**: 42 FPS on RTX 3080
- **Memory Usage**: 2.1GB GPU memory
- **Accuracy**: 78.9% mAP@0.5 on test dataset

## Research Impact and Applications

### Practical Applications

Our research has potential applications in:

1. **Traffic Monitoring**: Vehicle detection in urban areas
2. **Disaster Response**: Damage assessment from aerial imagery
3. **Environmental Monitoring**: Wildlife tracking and conservation
4. **Agricultural Analysis**: Crop health and equipment monitoring

### Academic Contributions

- **Novel Architecture**: FFCA module for enhanced feature representation
- **Benchmark Results**: State-of-the-art performance on small object datasets
- **Open Source**: Code and models available for research community

## Challenges and Learnings

### Technical Challenges

1. **Memory Constraints**: Large high-resolution images require careful memory management
2. **Training Stability**: Balancing detection accuracy across different object sizes
3. **Hyperparameter Tuning**: Finding optimal settings for diverse datasets

### Research Skills Developed

- **Deep Learning**: Advanced CNN architectures and attention mechanisms
- **Computer Vision**: Object detection, feature extraction, and image processing
- **Research Methodology**: Literature review, experimentation, and result analysis
- **Technical Writing**: Paper preparation and documentation

## Future Directions

### Immediate Improvements

- **Transformer Integration**: Exploring vision transformers for better feature representation
- **Multi-Modal Fusion**: Combining RGB and infrared imagery
- **Edge Deployment**: Optimizing for mobile and embedded devices

### Long-term Research Goals

- **3D Object Detection**: Extending to volumetric data from LiDAR
- **Temporal Modeling**: Video-based object tracking and prediction
- **Federated Learning**: Distributed training across multiple institutions

## Conclusion

My research internship at IIT Mandi has been an incredible learning experience. Working on cutting-edge computer vision problems has deepened my understanding of deep learning and its real-world applications.

The FFCA-YOLO model represents a significant step forward in small object detection for remote sensing applications. The combination of feature fusion and channel attention mechanisms provides a robust solution for challenging detection scenarios.

I'm grateful to my research supervisors and the IIT Mandi team for their guidance and support throughout this journey. This experience has solidified my passion for AI research and its potential to solve complex real-world problems.

## Acknowledgments

Special thanks to:
- **IIT Mandi Research Team**: For providing guidance and resources
- **Computer Vision Lab**: For access to computational infrastructure
- **Fellow Researchers**: For valuable discussions and feedback

---

*This research work is part of my ongoing commitment to advancing computer vision technology for practical applications. Stay tuned for more updates on this exciting project!*